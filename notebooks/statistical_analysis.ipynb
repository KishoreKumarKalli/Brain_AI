{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-31T06:19:43.994157Z",
     "start_time": "2025-03-31T06:19:41.479899Z"
    }
   },
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from statsmodels.formula.api import ols\n",
    "import nibabel as nib\n",
    "from nilearn import plotting, image\n",
    "import pingouin as pg\n",
    "import yaml\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import project modules\n",
    "from src.analysis.statistics import (\n",
    "    compute_brain_volume_stats, \n",
    "    compare_groups, \n",
    "    correlate_imaging_clinical,\n",
    "    longitudinal_analysis\n",
    ")\n",
    "from src.utils.metrics import classification_metrics, segmentation_metrics\n",
    "from src.analysis.reporting import generate_statistical_report\n",
    "\n",
    "# Load configuration\n",
    "with open(\"../config.yml\", 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# Set the plotting style\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Define paths\n",
    "data_dir = config['data']['processed_dir']\n",
    "results_dir = config['analysis']['results_dir']\n",
    "clinical_dir = config['data']['clinical_dir']\n",
    "model_dir = config['models']['checkpoints_dir']\n",
    "\n",
    "# Create results directory if it doesn't exist\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Load the clinical data\n",
    "print(\"Loading clinical data...\")\n",
    "\n",
    "# Subject information\n",
    "adni_t1 = pd.read_csv(os.path.join(clinical_dir, 'ADNI_T1.csv'))\n",
    "print(f\"ADNI T1 dataset: {adni_t1.shape[0]} subjects\")\n",
    "\n",
    "# Clinical assessment data\n",
    "cdr = pd.read_csv(os.path.join(clinical_dir, 'CDR.csv'))\n",
    "mmse = pd.read_csv(os.path.join(clinical_dir, 'MMSE.csv'))\n",
    "gdscale = pd.read_csv(os.path.join(clinical_dir, 'GDSCALE.csv'))\n",
    "adas_adni1 = pd.read_csv(os.path.join(clinical_dir, 'ADAS_ADNI1.csv'))\n",
    "adas_adnigo23 = pd.read_csv(os.path.join(clinical_dir, 'ADAS_ADNIGO23.csv'))\n",
    "neurobat = pd.read_csv(os.path.join(clinical_dir, 'NEUROBAT.csv'))\n",
    "demographics = pd.read_csv(os.path.join(clinical_dir, 'PTDEMOG.csv'))\n",
    "\n",
    "# Display basic information about datasets\n",
    "print(f\"CDR dataset: {cdr.shape[0]} records\")\n",
    "print(f\"MMSE dataset: {mmse.shape[0]} records\")\n",
    "print(f\"GD Scale dataset: {gdscale.shape[0]} records\")\n",
    "print(f\"ADAS ADNI1 dataset: {adas_adni1.shape[0]} records\")\n",
    "print(f\"ADAS ADNIGO2/3 dataset: {adas_adnigo23.shape[0]} records\")\n",
    "print(f\"Neurobat dataset: {neurobat.shape[0]} records\")\n",
    "print(f\"Demographics dataset: {demographics.shape[0]} records\")\n",
    "\n",
    "# Load the segmentation and prediction results\n",
    "print(\"\\nLoading model prediction results...\")\n",
    "segmentation_results = pd.read_csv(os.path.join(results_dir, 'segmentation_volumes.csv'))\n",
    "anomaly_results = pd.read_csv(os.path.join(results_dir, 'anomaly_detection_results.csv'))\n",
    "\n",
    "# Merge model results with clinical data\n",
    "print(\"Merging datasets...\")\n",
    "merged_data = (\n",
    "    adni_t1\n",
    "    .merge(segmentation_results, on='Subject_ID', how='inner')\n",
    "    .merge(anomaly_results, on='Subject_ID', how='inner')\n",
    ")\n",
    "\n",
    "# Add key clinical measures\n",
    "merged_data = (\n",
    "    merged_data\n",
    "    .merge(mmse[['Subject_ID', 'MMSE_Total']], on='Subject_ID', how='left')\n",
    "    .merge(cdr[['Subject_ID', 'CDR_Global']], on='Subject_ID', how='left')\n",
    "    .merge(demographics[['Subject_ID', 'Age', 'Gender', 'Education']], on='Subject_ID', how='left')\n",
    ")\n",
    "\n",
    "print(f\"Final merged dataset: {merged_data.shape[0]} subjects with {merged_data.shape[1]} variables\")\n",
    "\n",
    "# Display distribution of diagnostic groups in the merged dataset\n",
    "diagnosis_count = merged_data['Diagnosis'].value_counts()\n",
    "print(\"\\nDiagnostic group distribution in merged dataset:\")\n",
    "print(diagnosis_count)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='Diagnosis', data=merged_data, palette='viridis')\n",
    "plt.title('Distribution of Diagnostic Groups')\n",
    "plt.xlabel('Diagnosis')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_dir, 'diagnosis_distribution.png'), dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Descriptive statistics of brain volumes by diagnostic group\n",
    "print(\"\\n1. Descriptive Statistics of Brain Volumes by Diagnostic Group\")\n",
    "\n",
    "# Select key brain structures\n",
    "key_structures = ['Gray_Matter_Volume', 'White_Matter_Volume', 'Hippocampus_Volume',\n",
    "                 'Ventricles_Volume', 'Total_Brain_Volume', 'Abnormality_Score']\n",
    "\n",
    "# Group by diagnosis and compute stats\n",
    "volume_stats = merged_data.groupby('Diagnosis')[key_structures].agg(['mean', 'std', 'min', 'max'])\n",
    "print(volume_stats)\n",
    "\n",
    "# Create boxplots\n",
    "plt.figure(figsize=(18, 12))\n",
    "for i, structure in enumerate(key_structures):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    sns.boxplot(x='Diagnosis', y=structure, data=merged_data, palette='viridis')\n",
    "    plt.title(f'{structure} by Diagnosis')\n",
    "    plt.xlabel('Diagnosis')\n",
    "    plt.ylabel('Volume (mm³)' if 'Volume' in structure else 'Score')\n",
    "    plt.xticks(rotation=0)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_dir, 'volume_boxplots.png'), dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# 2. Statistical Comparisons Between Groups\n",
    "print(\"\\n2. Statistical Testing: Comparing Brain Volumes Between Diagnostic Groups\")\n",
    "\n",
    "# ANOVA for each brain structure\n",
    "anova_results = {}\n",
    "tukey_results = {}\n",
    "\n",
    "for structure in key_structures:\n",
    "    # ANOVA\n",
    "    model = ols(f'{structure} ~ Diagnosis', data=merged_data).fit()\n",
    "    anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "    anova_results[structure] = anova_table\n",
    "    \n",
    "    # Post-hoc Tukey test\n",
    "    tukey = pairwise_tukeyhsd(endog=merged_data[structure], groups=merged_data['Diagnosis'], alpha=0.05)\n",
    "    tukey_results[structure] = tukey\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\nANOVA for {structure}:\")\n",
    "    print(anova_table)\n",
    "    \n",
    "    print(f\"\\nTukey HSD for {structure}:\")\n",
    "    print(tukey)\n",
    "    \n",
    "    # Visualization\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='Diagnosis', y=structure, data=merged_data, palette='viridis', \n",
    "                ci=95, capsize=0.2)\n",
    "    plt.title(f'{structure} Comparison (p={anova_table[\"PR(>F)\"][0]:.4f})')\n",
    "    plt.xlabel('Diagnosis')\n",
    "    plt.ylabel('Volume (mm³)' if 'Volume' in structure else 'Score')\n",
    "    \n",
    "    # Add p-value annotations\n",
    "    p_value = anova_table[\"PR(>F)\"][0]\n",
    "    significance = \"\"\n",
    "    if p_value < 0.001:\n",
    "        significance = \"***\"\n",
    "    elif p_value < 0.01:\n",
    "        significance = \"**\"\n",
    "    elif p_value < 0.05:\n",
    "        significance = \"*\"\n",
    "        \n",
    "    plt.text(0.5, 0.9, f'ANOVA: p={p_value:.4f} {significance}', \n",
    "             horizontalalignment='center', transform=plt.gca().transAxes)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(results_dir, f'{structure}_comparison.png'), dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "# 3. Correlation Analysis: Brain Volumes and Clinical Scores\n",
    "print(\"\\n3. Correlation Analysis: Brain Volumes and Clinical Scores\")\n",
    "\n",
    "# Select the columns for correlation analysis\n",
    "clinical_measures = ['MMSE_Total', 'CDR_Global', 'Age', 'Education']\n",
    "correlation_vars = key_structures + clinical_measures\n",
    "\n",
    "# Create correlation matrix\n",
    "corr_matrix = merged_data[correlation_vars].corr(method='spearman')\n",
    "print(\"Spearman correlation matrix:\")\n",
    "print(corr_matrix)\n",
    "\n",
    "# Plot correlation heatmap\n",
    "plt.figure(figsize=(14, 12))\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "sns.heatmap(corr_matrix, annot=True, mask=mask, cmap=cmap, vmax=1, vmin=-1, \n",
    "            center=0, square=True, linewidths=.5, fmt='.2f', cbar_kws={\"shrink\": .8})\n",
    "plt.title('Spearman Correlation: Brain Volumes vs. Clinical Measures', fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_dir, 'correlation_heatmap.png'), dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Scatter plots for key relationships\n",
    "key_correlations = [\n",
    "    ('Hippocampus_Volume', 'MMSE_Total'),\n",
    "    ('Gray_Matter_Volume', 'MMSE_Total'),\n",
    "    ('Abnormality_Score', 'CDR_Global'),\n",
    "    ('Total_Brain_Volume', 'Age')\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(18, 12))\n",
    "for i, (x_var, y_var) in enumerate(key_correlations):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    sns.scatterplot(x=x_var, y=y_var, hue='Diagnosis', data=merged_data, palette='viridis', alpha=0.7)\n",
    "    \n",
    "    # Calculate correlation and display it\n",
    "    corr, p_val = stats.spearmanr(merged_data[x_var], merged_data[y_var], nan_policy='omit')\n",
    "    significance = \"\"\n",
    "    if p_val < 0.001:\n",
    "        significance = \"***\"\n",
    "    elif p_val < 0.01:\n",
    "        significance = \"**\"\n",
    "    elif p_val < 0.05:\n",
    "        significance = \"*\"\n",
    "        \n",
    "    plt.title(f'{x_var} vs {y_var}\\nr={corr:.2f}, p={p_val:.4f} {significance}')\n",
    "    plt.xlabel(x_var)\n",
    "    plt.ylabel(y_var)\n",
    "    plt.legend(loc='best')\n",
    "    \n",
    "    # Add regression line\n",
    "    sns.regplot(x=x_var, y=y_var, data=merged_data, scatter=False, \n",
    "                line_kws={'color': 'black', 'linestyle': '--'})\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_dir, 'key_correlations.png'), dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# 4. Classification Performance Analysis\n",
    "print(\"\\n4. Classification Performance Analysis\")\n",
    "\n",
    "# Evaluate model classification performance\n",
    "y_true = pd.get_dummies(merged_data['Diagnosis'])\n",
    "y_pred_proba = merged_data[['CN_Probability', 'MCI_Probability', 'AD_Probability']]\n",
    "\n",
    "# Calculate ROC curves\n",
    "plt.figure(figsize=(12, 10))\n",
    "colors = ['blue', 'green', 'red']\n",
    "classes = ['CN', 'MCI', 'AD']\n",
    "\n",
    "for i, (cls, color) in enumerate(zip(classes, colors)):\n",
    "    fpr, tpr, _ = roc_curve(y_true[cls], y_pred_proba[f'{cls}_Probability'])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, color=color, lw=2,\n",
    "             label=f'ROC curve for {cls} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves for Multi-class Classification')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_dir, 'roc_curves.png'), dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Confusion matrix\n",
    "y_pred_class = merged_data['Predicted_Diagnosis']\n",
    "y_true_class = merged_data['Diagnosis']\n",
    "cm = confusion_matrix(y_true_class, y_pred_class)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_normalized, annot=True, cmap='Blues', fmt='.2f',\n",
    "            xticklabels=classes, yticklabels=classes)\n",
    "plt.title('Normalized Confusion Matrix')\n",
    "plt.xlabel('Predicted Diagnosis')\n",
    "plt.ylabel('True Diagnosis')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_dir, 'confusion_matrix.png'), dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Calculate classification metrics\n",
    "accuracy = np.mean(y_pred_class == y_true_class)\n",
    "print(f\"Overall accuracy: {accuracy:.3f}\")\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true_class, y_pred_class))\n",
    "\n",
    "# 5. Multivariate Analysis\n",
    "print(\"\\n5. Principal Component Analysis of Brain Volumes\")\n",
    "\n",
    "# Select features for PCA\n",
    "pca_features = [col for col in merged_data.columns if 'Volume' in col]\n",
    "X = merged_data[pca_features]\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=2)\n",
    "principal_components = pca.fit_transform(X_scaled)\n",
    "pca_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])\n",
    "pca_df['Diagnosis'] = merged_data['Diagnosis']\n",
    "\n",
    "# Visualize PCA results\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.scatterplot(x='PC1', y='PC2', hue='Diagnosis', data=pca_df, palette='viridis', s=100, alpha=0.7)\n",
    "plt.title('PCA of Brain Volume Measurements')\n",
    "plt.xlabel(f'Principal Component 1 ({pca.explained_variance_ratio_[0]:.2%} variance)')\n",
    "plt.ylabel(f'Principal Component 2 ({pca.explained_variance_ratio_[1]:.2%} variance)')\n",
    "plt.legend(title='Diagnosis')\n",
    "\n",
    "# Add arrows for feature loadings\n",
    "features = pca_features\n",
    "loadings = pca.components_.T * np.sqrt(pca.explained_variance_)\n",
    "\n",
    "for i, feature in enumerate(features):\n",
    "    plt.arrow(0, 0, loadings[i, 0], loadings[i, 1], head_width=0.05, head_length=0.05, fc='gray', ec='gray')\n",
    "    plt.text(loadings[i, 0] * 1.15, loadings[i, 1] * 1.15, feature, \n",
    "             color='black', ha='center', va='center', fontsize=10)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_dir, 'pca_brain_volumes.png'), dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# 6. Statistical Analysis of Anomaly Detection\n",
    "print(\"\\n6. Statistical Analysis of Anomaly Detection\")\n",
    "\n",
    "# Compare abnormality scores across diagnostic groups\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='Diagnosis', y='Abnormality_Score', data=merged_data, palette='viridis')\n",
    "plt.title('Abnormality Scores by Diagnostic Group')\n",
    "plt.xlabel('Diagnosis')\n",
    "plt.ylabel('Abnormality Score')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_dir, 'abnormality_scores.png'), dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# ANOVA for abnormality scores\n",
    "anova_model = ols('Abnormality_Score ~ Diagnosis', data=merged_data).fit()\n",
    "anova_table = sm.stats.anova_lm(anova_model, typ=2)\n",
    "print(\"ANOVA for Abnormality Scores:\")\n",
    "print(anova_table)\n",
    "\n",
    "# Tukey's test for post-hoc analysis\n",
    "tukey = pairwise_tukeyhsd(endog=merged_data['Abnormality_Score'], \n",
    "                         groups=merged_data['Diagnosis'], \n",
    "                         alpha=0.05)\n",
    "print(\"\\nTukey HSD for Abnormality Scores:\")\n",
    "print(tukey)\n",
    "\n",
    "# Plot Tukey's test results\n",
    "tukey_df = pd.DataFrame(data=tukey._results_table.data[1:], \n",
    "                       columns=tukey._results_table.data[0])\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(pd.crosstab(tukey_df['group1'], tukey_df['group2'], \n",
    "                        values=tukey_df['p-adj'].astype(float), \n",
    "                        aggfunc='mean').fillna(1.0),\n",
    "           annot=True, cmap='coolwarm_r', vmin=0, vmax=0.05)\n",
    "plt.title(\"Tukey's HSD p-values for Abnormality Scores\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_dir, 'tukey_heatmap.png'), dpi=300)\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'compute_brain_volume_stats' from 'src.analysis.statistics' (D:\\KLU 4th YEAR\\Projects\\Brain_AI\\src\\analysis\\statistics.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mImportError\u001B[39m                               Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 24\u001B[39m\n\u001B[32m     21\u001B[39m sys.path.append(\u001B[33m'\u001B[39m\u001B[33m..\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m     23\u001B[39m \u001B[38;5;66;03m# Import project modules\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m24\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msrc\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01manalysis\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mstatistics\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m     25\u001B[39m     compute_brain_volume_stats, \n\u001B[32m     26\u001B[39m     compare_groups, \n\u001B[32m     27\u001B[39m     correlate_imaging_clinical,\n\u001B[32m     28\u001B[39m     longitudinal_analysis\n\u001B[32m     29\u001B[39m )\n\u001B[32m     30\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msrc\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mmetrics\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m classification_metrics, segmentation_metrics\n\u001B[32m     31\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msrc\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01manalysis\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mreporting\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m generate_statistical_report\n",
      "\u001B[31mImportError\u001B[39m: cannot import name 'compute_brain_volume_stats' from 'src.analysis.statistics' (D:\\KLU 4th YEAR\\Projects\\Brain_AI\\src\\analysis\\statistics.py)"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "916bdd8084ee97b6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
